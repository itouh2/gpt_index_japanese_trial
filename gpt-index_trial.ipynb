{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_index import LLMPredictor\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Mapping, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PROMPT = \"\"\"\n",
    "文脈情報は以下です。\n",
    "---\n",
    "{context_str}\n",
    "---\n",
    "事前知識ではなく、文脈情報を参考に質問に答えてください。：{query_str}\n",
    "\"\"\"\n",
    "\n",
    "REFINE_PROMPT = \"\"\"\n",
    "質問は以下です。：{query_str}\n",
    "すでに答えの候補があります。：{existing_answer}\n",
    "必要な場合のみ、以下の文脈情報を使ってこの答えを改良することができます。\n",
    "---\n",
    "{context_msg}\n",
    "---\n",
    "この文脈情報により、元の答えを改良して質問に答えてください。\n",
    "文脈情報が有用でない場合は元の答えをそのまま返してください。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt-1b\")\n",
    "qa_model = AutoModelForCausalLM.from_pretrained(\"oshizo/qa-refine-japanese-gpt-1b\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    qa_model = qa_model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "\n",
    "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    n = len(token_ids[0])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = qa_model.generate(\n",
    "            token_ids.to(qa_model.device),\n",
    "            max_length=n+100,\n",
    "            min_length=n+2,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    output = tokenizer.decode(output_ids.tolist()[0][n:])\n",
    "    return output.replace(\"</s>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "    \n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        return generate(prompt)\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"name\":\"custom\"}\n",
    "llm = CustomLLM()\n",
    "llm_predictor = LLMPredictor(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from gpt_index import LangchainEmbedding\n",
    "\n",
    "# load in HF embedding model from langchain\n",
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embed_model._langchain_embedding.client = SentenceTransformer(\"oshizo/sbert-jsnli-luke-japanese-base-lite\")\n",
    "embed_model._langchain_embedding.client.max_seq_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "url = \"https://ja.wikipedia.org/wiki/%E3%81%BC%E3%81%A3%E3%81%A1%E3%83%BB%E3%81%96%E3%83%BB%E3%82%8D%E3%81%A3%E3%81%8F!?action=cirrusdump\"\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    data = f.read()\n",
    "text = json.loads(data)[0][\"_source\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_index import GPTSimpleVectorIndex\n",
    "from gpt_index.readers.schema.base import Document\n",
    "documents = []\n",
    "for i in range(0, len(text), 200):\n",
    "    documents.append(Document(text[i:i+200]))\n",
    "    if i != 0:\n",
    "        documents.append(Document(text[i-100:i+100]))\n",
    "# インデックスの作成\n",
    "index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_index.prompts.base import Prompt\n",
    "from gpt_index.prompts.prompts import RefinePrompt, QuestionAnswerPrompt\n",
    "refine_prompt = RefinePrompt(REFINE_PROMPT)\n",
    "default_prompt = QuestionAnswerPrompt(DEFAULT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node 861c16bc-553f-47e7-a1e0-55cd5fda9bb6] 地知 星歌（いじち せいか） 声 - 内田真礼 虹夏の姉で、ライブハウス「STARRY」の店長。クリスマスイブが誕生日で、作中1年目に30歳を迎えた。かつては自身もバンドマン（ギタリスト）で、そ...\n",
      "> [Node 6de817d0-b70a-417f-aae6-a02c0b233c64]  鈴代紗弓 誕生日：5月29日 / 血液型：A型 ドラム担当。下北沢高校2年→3年。明るく世話焼きで、バンドのまとめ役。水玉のリボンがトレードマークで、たいてい身体のどこかに身につけている。姉の...\n",
      "> Searching in chunk: 地知 星歌（いじち せいか） 声 - 内田真礼 虹夏の姉で、ライブハウス「STARRY」の店長...\n",
      "> Searching in chunk:  鈴代紗弓 誕生日：5月29日 / 血液型：A型 ドラム担当。下北沢高校2年→3年。明るく世話...\n",
      "> Initial response: ライブハウス「STARRY」の店長\n",
      "> Refine context:  鈴代紗弓 誕生日：5月29日 / 血液型：A型 ドラム担当。下北沢高校2年→3年。明るく世話...\n",
      "> Refined response: ライブハウス「STARRY」の店長\n",
      "> [query] Total LLM token usage: 931 tokens\n",
      "> [query] Total embedding token usage: 26 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ライブハウス「STARRY」の店長'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = index.query(\n",
    "    \"虹夏ちゃんのお姉さんの仕事は？\", \n",
    "    mode=\"embedding\", \n",
    "    verbose=True, \n",
    "    embed_model=embed_model,\n",
    "    text_qa_template=default_prompt,\n",
    "    refine_template=refine_prompt,\n",
    "    similarity_top_k=2\n",
    ")\n",
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node a81cd7ff-99b6-42a9-bc72-5e35d5c0c1f5] レックスを持っていたところ、中学1年の時に、暗い学生時代から一転してスターとなったバンドマンのインタビューを目にしたことで、父親から借りたギターに没頭する。毎日6時間以上の練習を約3年間欠かさず...\n",
      "> [Node 4b2fd373-68fe-4830-9161-246f88257149] である所謂「陽キャラ」および「パリピ」に強い偏見を抱いており、虹夏や喜多らを自分にとってのヒール役に見立てた妄想をすることがある。 先述の性格に加え、運動、勉強など取り柄と言えるものがないという...\n",
      "> Searching in chunk: レックスを持っていたところ、中学1年の時に、暗い学生時代から一転してスターとなったバンドマンの...\n",
      "> Searching in chunk: である所謂「陽キャラ」および「パリピ」に強い偏見を抱いており、虹夏や喜多らを自分にとってのヒー...\n",
      "> Initial response: 暗い学生時代から一転してスターとなったバンドマンのインタビュー\n",
      "> Refine context: である所謂「陽キャラ」および「パリピ」に強い偏見を抱いており、虹夏や喜多らを自分にとってのヒー...\n",
      "> Refined response: 暗い学生時代から一転してスターとなったバンドマンのインタビュー\n",
      "> [query] Total LLM token usage: 1045 tokens\n",
      "> [query] Total embedding token usage: 45 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'暗い学生時代から一転してスターとなったバンドマンのインタビュー'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = index.query(\n",
    "    \"後藤ひとりがギターに熱中するようになった理由になった出来事は？\", \n",
    "    mode=\"embedding\", \n",
    "    verbose=True, \n",
    "    embed_model=embed_model,\n",
    "    text_qa_template=default_prompt,\n",
    "    refine_template=refine_prompt,\n",
    "    similarity_top_k=2\n",
    ")\n",
    "response.response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f654d66d151deba9457e27d06730dde595b930a8810fc70e1b9eaf1b703f5dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
